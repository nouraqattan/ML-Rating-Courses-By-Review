{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "SVChm60whYVo",
        "outputId": "df921d7e-1872-4ed9-e1d9-2d7da7183915"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>good and interesting</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This class is very helpful to me. Currently, I...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Easy to follow and includes a lot basic and im...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Really nice teacher!I could got the point eazl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107013</th>\n",
              "      <td>107013</td>\n",
              "      <td>Trendy topic with talks from expertises in the...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107014</th>\n",
              "      <td>107014</td>\n",
              "      <td>Wonderful! Simple and clear language, good ins...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107015</th>\n",
              "      <td>107015</td>\n",
              "      <td>an interesting and fun course. thanks. dr quincy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107016</th>\n",
              "      <td>107016</td>\n",
              "      <td>very broad perspective, up to date information...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107017</th>\n",
              "      <td>107017</td>\n",
              "      <td>An informative course on the social and financ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107018 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id                                             Review  Label\n",
              "0            0                               good and interesting      5\n",
              "1            1  This class is very helpful to me. Currently, I...      5\n",
              "2            2  like!Prof and TAs are helpful and the discussi...      5\n",
              "3            3  Easy to follow and includes a lot basic and im...      5\n",
              "4            4  Really nice teacher!I could got the point eazl...      4\n",
              "...        ...                                                ...    ...\n",
              "107013  107013  Trendy topic with talks from expertises in the...      4\n",
              "107014  107014  Wonderful! Simple and clear language, good ins...      5\n",
              "107015  107015   an interesting and fun course. thanks. dr quincy      5\n",
              "107016  107016  very broad perspective, up to date information...      4\n",
              "107017  107017  An informative course on the social and financ...      4\n",
              "\n",
              "[107018 rows x 3 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'd:\\Desktop\\reports\\datasets\\course_review\\reviews.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ubC0vtpvhkKs",
        "outputId": "d0de6e79-14f6-4c6d-9587-7c6ad1240a8a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good and interesting</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This class is very helpful to me. Currently, I...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Easy to follow and includes a lot basic and im...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really nice teacher!I could got the point eazl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Label\n",
              "0                               good and interesting      5\n",
              "1  This class is very helpful to me. Currently, I...      5\n",
              "2  like!Prof and TAs are helpful and the discussi...      5\n",
              "3  Easy to follow and includes a lot basic and im...      5\n",
              "4  Really nice teacher!I could got the point eazl...      4"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.drop(columns=['Id'] , inplace= True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BqOINvqhsl8",
        "outputId": "4a441fa9-6128-4b23-ee48-d67deeca796b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of null rows: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for null values in each row\n",
        "null_rows = df.isnull().any(axis=1)\n",
        "\n",
        "# Count the number of null rows\n",
        "num_null_rows = null_rows.sum()\n",
        "\n",
        "# Print the number of null rows\n",
        "print(\"Number of null rows:\", num_null_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP7pH0kwh5Gn",
        "outputId": "97438a07-8942-4f26-9e4a-d890cc99d046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "5    79173\n",
            "4    18054\n",
            "3     5071\n",
            "1     2469\n",
            "2     2251\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "label_count = df['Label'].value_counts()\n",
        "print(label_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ihg5B0dwiCLg",
        "outputId": "fbde317e-9afe-4e16-b0b1-a37fc94f63b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good and interesting</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This class is very helpful to me. Currently, I...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Easy to follow and includes a lot basic and im...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really nice teacher!I could got the point eazl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107013</th>\n",
              "      <td>Trendy topic with talks from expertises in the...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107014</th>\n",
              "      <td>Wonderful! Simple and clear language, good ins...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107015</th>\n",
              "      <td>an interesting and fun course. thanks. dr quincy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107016</th>\n",
              "      <td>very broad perspective, up to date information...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107017</th>\n",
              "      <td>An informative course on the social and financ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107018 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Review  Label\n",
              "0                                    good and interesting      5\n",
              "1       This class is very helpful to me. Currently, I...      5\n",
              "2       like!Prof and TAs are helpful and the discussi...      5\n",
              "3       Easy to follow and includes a lot basic and im...      5\n",
              "4       Really nice teacher!I could got the point eazl...      4\n",
              "...                                                   ...    ...\n",
              "107013  Trendy topic with talks from expertises in the...      4\n",
              "107014  Wonderful! Simple and clear language, good ins...      5\n",
              "107015   an interesting and fun course. thanks. dr quincy      5\n",
              "107016  very broad perspective, up to date information...      4\n",
              "107017  An informative course on the social and financ...      4\n",
              "\n",
              "[107018 rows x 2 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qR6dnlO2ewGD",
        "outputId": "63323d36-b943-490c-dff7-5fe99eab35aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good and interesting</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This class is very helpful to me. Currently, I...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Easy to follow and includes a lot basic and im...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really nice teacher!I could got the point eazl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107013</th>\n",
              "      <td>Trendy topic with talks from expertises in the...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107014</th>\n",
              "      <td>Wonderful! Simple and clear language, good ins...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107015</th>\n",
              "      <td>an interesting and fun course. thanks. dr quincy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107016</th>\n",
              "      <td>very broad perspective, up to date information...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107017</th>\n",
              "      <td>An informative course on the social and financ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107018 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Review  Label\n",
              "0                                    good and interesting      5\n",
              "1       This class is very helpful to me. Currently, I...      5\n",
              "2       like!Prof and TAs are helpful and the discussi...      5\n",
              "3       Easy to follow and includes a lot basic and im...      5\n",
              "4       Really nice teacher!I could got the point eazl...      4\n",
              "...                                                   ...    ...\n",
              "107013  Trendy topic with talks from expertises in the...      4\n",
              "107014  Wonderful! Simple and clear language, good ins...      5\n",
              "107015   an interesting and fun course. thanks. dr quincy      5\n",
              "107016  very broad perspective, up to date information...      4\n",
              "107017  An informative course on the social and financ...      4\n",
              "\n",
              "[107018 rows x 2 columns]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df['Label']\n",
        "X = df['Review']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "fDAoCZXOfETp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train , y_test = train_test_split(X , y , test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "hrLNmvFjlk4M"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove URLs, emails, and special characters\n",
        "    text = re.sub(r'http\\S+|www.\\S+|[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P99iE3CafTnz",
        "outputId": "9ace60da-134b-40e8-97e8-7f4c012073b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ixmQBqHfP8D",
        "outputId": "fdfe89e2-7e68-4dbe-bc7a-953a637fefbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                             good interest\n",
              "1         class help current im still learn class make l...\n",
              "2         likeprof ta help discus among student quit act...\n",
              "3         easi follow includ lot basic import techniqu u...\n",
              "4             realli nice teacheri could got point eazliy v\n",
              "                                ...                        \n",
              "107013    trendi topic talk expertis field cover area in...\n",
              "107014    wonder simpl clear languag good instructor gre...\n",
              "107015                   interest fun cours thank dr quinci\n",
              "107016    broad perspect date inform use link video good...\n",
              "107017    inform cours social financi implic due zika we...\n",
              "Name: Review, Length: 107018, dtype: object"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = X.apply(preprocess_text)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jftmvDjfhm6A"
      },
      "source": [
        "### ***`Preprocessing`***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SYvA6vVhqDs",
        "outputId": "179e2af4-e8b7-4a06-bb19-72775b60500d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m91RaoZJhwK6",
        "outputId": "51bfb4ff-bb2f-4f7b-a3f3-5e3c7b84a375"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good and interesting</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this class is very helpful to me. currently, i...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like!prof and tas are helpful and the discussi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>easy to follow and includes a lot basic and im...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>really nice teacher!i could got the point eazl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107013</th>\n",
              "      <td>trendy topic with talks from expertises in the...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107014</th>\n",
              "      <td>wonderful! simple and clear language, good ins...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107015</th>\n",
              "      <td>an interesting and fun course. thanks. dr quincy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107016</th>\n",
              "      <td>very broad perspective, up to date information...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107017</th>\n",
              "      <td>an informative course on the social and financ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107018 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Review Label\n",
              "0                                    good and interesting     5\n",
              "1       this class is very helpful to me. currently, i...     5\n",
              "2       like!prof and tas are helpful and the discussi...     5\n",
              "3       easy to follow and includes a lot basic and im...     5\n",
              "4       really nice teacher!i could got the point eazl...     4\n",
              "...                                                   ...   ...\n",
              "107013  trendy topic with talks from expertises in the...     4\n",
              "107014  wonderful! simple and clear language, good ins...     5\n",
              "107015   an interesting and fun course. thanks. dr quincy     5\n",
              "107016  very broad perspective, up to date information...     4\n",
              "107017  an informative course on the social and financ...     4\n",
              "\n",
              "[107018 rows x 2 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert all rows to lowercase\n",
        "df = df.apply(lambda x: x.astype(str).str.lower())\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQIpaxQgh1w9",
        "outputId": "e4b9b1cc-01d4-4de2-cec2-257aa6ffe7ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   Review Label  \\\n",
            "0                                    good and interesting     5   \n",
            "1       this class is very helpful to me. currently, i...     5   \n",
            "2       like!prof and tas are helpful and the discussi...     5   \n",
            "3       easy to follow and includes a lot basic and im...     5   \n",
            "4       really nice teacher!i could got the point eazl...     4   \n",
            "...                                                   ...   ...   \n",
            "107013  trendy topic with talks from expertises in the...     4   \n",
            "107014  wonderful! simple and clear language, good ins...     5   \n",
            "107015   an interesting and fun course. thanks. dr quincy     5   \n",
            "107016  very broad perspective, up to date information...     4   \n",
            "107017  an informative course on the social and financ...     4   \n",
            "\n",
            "                                 Tokenized_Stemmed_Review   10  100  abil  \\\n",
            "0                                       good and interest  0.0  0.0   0.0   \n",
            "1       thi class is veri help to me . current , i 'm ...  0.0  0.0   0.0   \n",
            "2       like ! prof and ta are help and the discuss am...  0.0  0.0   0.0   \n",
            "3       easi to follow and includ a lot basic and impo...  0.0  0.0   0.0   \n",
            "4       realli nice teacher ! i could got the point ea...  0.0  0.0   0.0   \n",
            "...                                                   ...  ...  ...   ...   \n",
            "107013  trendi topic with talk from expertis in the fi...  0.0  0.0   0.0   \n",
            "107014  wonder ! simpl and clear languag , good instru...  0.0  0.0   0.0   \n",
            "107015      an interest and fun cours . thank . dr quinci  0.0  0.0   0.0   \n",
            "107016  veri broad perspect , up to date inform , use ...  0.0  0.0   0.0   \n",
            "107017  an inform cours on the social and financi impl...  0.0  0.0   0.0   \n",
            "\n",
            "        abl  about  absolut  academ  ...  would  write  written  wrong  \\\n",
            "0       0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "1       0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "2       0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "3       0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "4       0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "...     ...    ...      ...     ...  ...    ...    ...      ...    ...   \n",
            "107013  0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "107014  0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "107015  0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "107016  0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "107017  0.0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0   \n",
            "\n",
            "        yaakov  year  yet       you  your  yourself  \n",
            "0          0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "1          0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "2          0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "3          0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "4          0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "...        ...   ...  ...       ...   ...       ...  \n",
            "107013     0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "107014     0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "107015     0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "107016     0.0   0.0  0.0  0.140961   0.0       0.0  \n",
            "107017     0.0   0.0  0.0  0.000000   0.0       0.0  \n",
            "\n",
            "[107018 rows x 1003 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Tokenization and stemming function\n",
        "def tokenize_and_stem(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmer = PorterStemmer()\n",
        "    stems = [stemmer.stem(token) for token in tokens]\n",
        "    return ' '.join(stems)\n",
        "\n",
        "# Apply tokenization and stemming on the 'Review' column\n",
        "df['Tokenized_Stemmed_Review'] = df['Review'].apply(tokenize_and_stem)\n",
        "\n",
        "# Apply TF-IDF with max_features\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Tokenized_Stemmed_Review'])\n",
        "\n",
        "# Convert TF-IDF matrix to DataFrame\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Concatenate the original columns with the TF-IDF DataFrame\n",
        "df = pd.concat([df, df_tfidf], axis=1)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "vSNwNg29oiHs",
        "outputId": "d6da66e3-8dbf-4325-adb9-a0fcb2dfc83b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "      <th>Tokenized_Stemmed_Review</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>about</th>\n",
              "      <th>absolut</th>\n",
              "      <th>academ</th>\n",
              "      <th>...</th>\n",
              "      <th>would</th>\n",
              "      <th>write</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yaakov</th>\n",
              "      <th>year</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good and interesting</td>\n",
              "      <td>5</td>\n",
              "      <td>good and interest</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this class is very helpful to me. currently, i...</td>\n",
              "      <td>5</td>\n",
              "      <td>thi class is veri help to me . current , i 'm ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like!prof and tas are helpful and the discussi...</td>\n",
              "      <td>5</td>\n",
              "      <td>like ! prof and ta are help and the discuss am...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>easy to follow and includes a lot basic and im...</td>\n",
              "      <td>5</td>\n",
              "      <td>easi to follow and includ a lot basic and impo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>really nice teacher!i could got the point eazl...</td>\n",
              "      <td>4</td>\n",
              "      <td>realli nice teacher ! i could got the point ea...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1003 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review Label  \\\n",
              "0                               good and interesting     5   \n",
              "1  this class is very helpful to me. currently, i...     5   \n",
              "2  like!prof and tas are helpful and the discussi...     5   \n",
              "3  easy to follow and includes a lot basic and im...     5   \n",
              "4  really nice teacher!i could got the point eazl...     4   \n",
              "\n",
              "                            Tokenized_Stemmed_Review   10  100  abil  abl  \\\n",
              "0                                  good and interest  0.0  0.0   0.0  0.0   \n",
              "1  thi class is veri help to me . current , i 'm ...  0.0  0.0   0.0  0.0   \n",
              "2  like ! prof and ta are help and the discuss am...  0.0  0.0   0.0  0.0   \n",
              "3  easi to follow and includ a lot basic and impo...  0.0  0.0   0.0  0.0   \n",
              "4  realli nice teacher ! i could got the point ea...  0.0  0.0   0.0  0.0   \n",
              "\n",
              "   about  absolut  academ  ...  would  write  written  wrong  yaakov  year  \\\n",
              "0    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0     0.0   0.0   \n",
              "1    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0     0.0   0.0   \n",
              "2    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0     0.0   0.0   \n",
              "3    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0     0.0   0.0   \n",
              "4    0.0      0.0     0.0  ...    0.0    0.0      0.0    0.0     0.0   0.0   \n",
              "\n",
              "   yet  you  your  yourself  \n",
              "0  0.0  0.0   0.0       0.0  \n",
              "1  0.0  0.0   0.0       0.0  \n",
              "2  0.0  0.0   0.0       0.0  \n",
              "3  0.0  0.0   0.0       0.0  \n",
              "4  0.0  0.0   0.0       0.0  \n",
              "\n",
              "[5 rows x 1003 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "hhOucYyPpBZe",
        "outputId": "a57c2605-12e2-4c9a-dc54-5f1bd069b886"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>about</th>\n",
              "      <th>absolut</th>\n",
              "      <th>academ</th>\n",
              "      <th>access</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>...</th>\n",
              "      <th>would</th>\n",
              "      <th>write</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yaakov</th>\n",
              "      <th>year</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label   10  100  abil  abl  about  absolut  academ  access  accomplish  ...  \\\n",
              "0     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "1     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "2     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "3     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "4     4  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "\n",
              "   would  write  written  wrong  yaakov  year  yet  you  your  yourself  \n",
              "0    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "1    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "2    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "3    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "4    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "\n",
              "[5 rows x 1001 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.drop(columns=['Review','Tokenized_Stemmed_Review'] , inplace= True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "JZdyePGVthum",
        "outputId": "e5191e79-374e-4295-c2b5-8fcf8557f2b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>about</th>\n",
              "      <th>absolut</th>\n",
              "      <th>academ</th>\n",
              "      <th>access</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>...</th>\n",
              "      <th>would</th>\n",
              "      <th>write</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yaakov</th>\n",
              "      <th>year</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label   10  100  abil  abl  about  absolut  academ  access  accomplish  ...  \\\n",
              "0     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "1     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "2     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "3     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "4     4  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0  ...   \n",
              "\n",
              "   would  write  written  wrong  yaakov  year  yet  you  your  yourself  \n",
              "0    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "1    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "2    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "3    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "4    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.0   0.0       0.0  \n",
              "\n",
              "[5 rows x 1001 columns]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "tKLC3hWHsOx7",
        "outputId": "f5676aa1-26f1-42b4-da12-6c93d1c99dcd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>about</th>\n",
              "      <th>absolut</th>\n",
              "      <th>academ</th>\n",
              "      <th>access</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>...</th>\n",
              "      <th>would</th>\n",
              "      <th>write</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yaakov</th>\n",
              "      <th>year</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107013</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107014</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107015</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107016</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.140961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107017</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107018 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label   10  100  abil  abl  about  absolut  academ  access  accomplish  \\\n",
              "0          5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "1          5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "2          5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "3          5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "4          4  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "...      ...  ...  ...   ...  ...    ...      ...     ...     ...         ...   \n",
              "107013     4  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "107014     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "107015     5  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "107016     4  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "107017     4  0.0  0.0   0.0  0.0    0.0      0.0     0.0     0.0         0.0   \n",
              "\n",
              "        ...  would  write  written  wrong  yaakov  year  yet       you  your  \\\n",
              "0       ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "1       ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "2       ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "3       ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "4       ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "...     ...    ...    ...      ...    ...     ...   ...  ...       ...   ...   \n",
              "107013  ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "107014  ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "107015  ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "107016  ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.140961   0.0   \n",
              "107017  ...    0.0    0.0      0.0    0.0     0.0   0.0  0.0  0.000000   0.0   \n",
              "\n",
              "        yourself  \n",
              "0            0.0  \n",
              "1            0.0  \n",
              "2            0.0  \n",
              "3            0.0  \n",
              "4            0.0  \n",
              "...          ...  \n",
              "107013       0.0  \n",
              "107014       0.0  \n",
              "107015       0.0  \n",
              "107016       0.0  \n",
              "107017       0.0  \n",
              "\n",
              "[107018 rows x 1001 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df['Label']\n",
        "X = df.loc[: , df.columns != 'Label']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "R9IuVgp9gse7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train , y_test = train_test_split(X , y , test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.12.3)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataset shape: Counter({'5': 7992, '4': 1756, '3': 468, '2': 248, '1': 238})\n",
            "Resampled dataset shape: Counter({'4': 7992, '5': 7992, '2': 7992, '3': 7992, '1': 7992})\n",
            "Original Label Counts:\n",
            " Label\n",
            "5    7992\n",
            "4    1756\n",
            "3     468\n",
            "2     248\n",
            "1     238\n",
            "Name: count, dtype: int64\n",
            "Resampled Label Counts:\n",
            " Label\n",
            "4    7992\n",
            "5    7992\n",
            "2    7992\n",
            "3    7992\n",
            "1    7992\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Sample a smaller subset of the data\n",
        "df_sampled = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "y = df_sampled['Label']\n",
        "X = df_sampled.drop(columns=['Label'])\n",
        "\n",
        "# Optimize data types\n",
        "X = X.astype('float32')\n",
        "\n",
        "# Apply SMOTE to resample the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Create a new DataFrame with the resampled data\n",
        "resampled_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Label')], axis=1)\n",
        "\n",
        "# Print the original and resampled label distributions\n",
        "print(f\"Original dataset shape: {Counter(y)}\")\n",
        "print(f\"Resampled dataset shape: {Counter(y_resampled)}\")\n",
        "\n",
        "# If you want to see the label count in DataFrame format\n",
        "original_label_count = df_sampled['Label'].value_counts()\n",
        "resampled_label_count = resampled_df['Label'].value_counts()\n",
        "\n",
        "print(\"Original Label Counts:\\n\", original_label_count)\n",
        "print(\"Resampled Label Counts:\\n\", resampled_label_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Ile4_6A8kSKY",
        "outputId": "608653f9-1244-4e0e-8b28-8788ca8eca78"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>about</th>\n",
              "      <th>absolut</th>\n",
              "      <th>academ</th>\n",
              "      <th>access</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>account</th>\n",
              "      <th>...</th>\n",
              "      <th>write</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yaakov</th>\n",
              "      <th>year</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39955</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39956</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39957</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39958</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130965</td>\n",
              "      <td>0.050359</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39959</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39960 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        10  100  abil  abl     about  absolut  academ  access  accomplish  \\\n",
              "0      0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "1      0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "2      0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "3      0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "4      0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "...    ...  ...   ...  ...       ...      ...     ...     ...         ...   \n",
              "39955  0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "39956  0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "39957  0.0  0.0   0.0  0.0  0.103826      0.0     0.0     0.0         0.0   \n",
              "39958  0.0  0.0   0.0  0.0  0.062143      0.0     0.0     0.0         0.0   \n",
              "39959  0.0  0.0   0.0  0.0  0.000000      0.0     0.0     0.0         0.0   \n",
              "\n",
              "       account  ...  write  written     wrong  yaakov  year  yet       you  \\\n",
              "0          0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "1          0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "2          0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "3          0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "4          0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "...        ...  ...    ...      ...       ...     ...   ...  ...       ...   \n",
              "39955      0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "39956      0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "39957      0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "39958      0.0  ...    0.0      0.0  0.038316     0.0   0.0  0.0  0.130965   \n",
              "39959      0.0  ...    0.0      0.0  0.000000     0.0   0.0  0.0  0.000000   \n",
              "\n",
              "           your  yourself  Label  \n",
              "0      0.000000       0.0      4  \n",
              "1      0.000000       0.0      4  \n",
              "2      0.000000       0.0      5  \n",
              "3      0.000000       0.0      5  \n",
              "4      0.000000       0.0      5  \n",
              "...         ...       ...    ...  \n",
              "39955  0.000000       0.0      4  \n",
              "39956  0.000000       0.0      4  \n",
              "39957  0.000000       0.0      4  \n",
              "39958  0.050359       0.0      4  \n",
              "39959  0.000000       0.0      4  \n",
              "\n",
              "[39960 rows x 1001 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resampled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTBu8lKpiN9s",
        "outputId": "04395fb2-93c3-43de-c8df-465a38209230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "4    7992\n",
            "5    7992\n",
            "2    7992\n",
            "3    7992\n",
            "1    7992\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "label_count = resampled_df['Label'].value_counts()\n",
        "print(label_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGGFISWY5YBl",
        "outputId": "3150b0b9-3698-48a2-958e-267fac05c23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(85614, 1000)\n",
            "(85614,)\n",
            "(21404, 1000)\n",
            "(21404,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79ccaWAspduj"
      },
      "source": [
        "### ***`ALGorithm`***\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DecisionTree Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 53.259509509509506\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.57      0.64      0.61      6393\n",
            "           2       0.62      0.57      0.59      6394\n",
            "           3       0.52      0.48      0.50      6394\n",
            "           4       0.39      0.34      0.36      6393\n",
            "           5       0.54      0.63      0.58      6394\n",
            "\n",
            "    accuracy                           0.53     31968\n",
            "   macro avg       0.53      0.53      0.53     31968\n",
            "weighted avg       0.53      0.53      0.53     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 51.97697697697697\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.56      0.62      0.59      1599\n",
            "           2       0.61      0.57      0.58      1598\n",
            "           3       0.51      0.47      0.49      1598\n",
            "           4       0.38      0.31      0.34      1599\n",
            "           5       0.52      0.63      0.57      1598\n",
            "\n",
            "    accuracy                           0.52      7992\n",
            "   macro avg       0.52      0.52      0.52      7992\n",
            "weighted avg       0.52      0.52      0.52      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Decision Tree Classifier with specified hyperparameters\n",
        "classifier = DecisionTreeClassifier(\n",
        "    max_depth=100,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    max_features='sqrt',\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.fit(X_batch, y_batch)\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 50.387887887887885\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.54      0.64      0.58      6393\n",
            "           2       0.46      0.64      0.53      6394\n",
            "           3       0.45      0.33      0.38      6394\n",
            "           4       0.44      0.33      0.38      6393\n",
            "           5       0.63      0.58      0.60      6394\n",
            "\n",
            "    accuracy                           0.50     31968\n",
            "   macro avg       0.50      0.50      0.50     31968\n",
            "weighted avg       0.50      0.50      0.50     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 49.73723723723724\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.55      0.62      0.58      1599\n",
            "           2       0.46      0.65      0.53      1598\n",
            "           3       0.43      0.32      0.37      1598\n",
            "           4       0.41      0.32      0.36      1599\n",
            "           5       0.62      0.58      0.60      1598\n",
            "\n",
            "    accuracy                           0.50      7992\n",
            "   macro avg       0.49      0.50      0.49      7992\n",
            "weighted avg       0.49      0.50      0.49      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Decision Tree Classifier with specified hyperparameters\n",
        "classifier = DecisionTreeClassifier(\n",
        "    criterion='gini',            # or 'entropy'\n",
        "    splitter='best',             # or 'random'\n",
        "    max_depth=2000,\n",
        "    min_samples_split=200,\n",
        "    min_samples_leaf=1,\n",
        "    max_features=None,           # or 'auto', 'sqrt', 'log2'\n",
        "    max_leaf_nodes=None,\n",
        "    min_impurity_decrease=0.0,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.fit(X_batch, y_batch)\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MLP Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 81.13113113113113\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.97      0.96      6393\n",
            "           2       0.90      0.92      0.91      6394\n",
            "           3       0.79      0.85      0.82      6394\n",
            "           4       0.68      0.52      0.59      6393\n",
            "           5       0.72      0.79      0.75      6394\n",
            "\n",
            "    accuracy                           0.81     31968\n",
            "   macro avg       0.81      0.81      0.81     31968\n",
            "weighted avg       0.81      0.81      0.81     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 80.70570570570571\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.97      0.96      1599\n",
            "           2       0.90      0.93      0.92      1598\n",
            "           3       0.78      0.85      0.81      1598\n",
            "           4       0.66      0.50      0.57      1599\n",
            "           5       0.71      0.79      0.75      1598\n",
            "\n",
            "    accuracy                           0.81      7992\n",
            "   macro avg       0.80      0.81      0.80      7992\n",
            "weighted avg       0.80      0.81      0.80      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 87.42492492492492\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.99      0.99      6393\n",
            "           2       0.98      0.98      0.98      6394\n",
            "           3       0.88      0.92      0.90      6394\n",
            "           4       0.78      0.64      0.70      6393\n",
            "           5       0.75      0.84      0.79      6394\n",
            "\n",
            "    accuracy                           0.87     31968\n",
            "   macro avg       0.87      0.87      0.87     31968\n",
            "weighted avg       0.87      0.87      0.87     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 85.86086086086087\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.99      0.98      1599\n",
            "           2       0.97      0.98      0.97      1598\n",
            "           3       0.87      0.91      0.89      1598\n",
            "           4       0.74      0.60      0.67      1599\n",
            "           5       0.72      0.81      0.76      1598\n",
            "\n",
            "    accuracy                           0.86      7992\n",
            "   macro avg       0.86      0.86      0.86      7992\n",
            "weighted avg       0.86      0.86      0.86      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(300, 100),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 88.34772272272272\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      0.99      6393\n",
            "           2       0.98      0.99      0.98      6394\n",
            "           3       0.90      0.94      0.92      6394\n",
            "           4       0.81      0.63      0.71      6393\n",
            "           5       0.74      0.86      0.80      6394\n",
            "\n",
            "    accuracy                           0.88     31968\n",
            "   macro avg       0.88      0.88      0.88     31968\n",
            "weighted avg       0.88      0.88      0.88     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 87.14964964964965\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.99      0.99      1599\n",
            "           2       0.97      0.99      0.98      1598\n",
            "           3       0.90      0.93      0.91      1598\n",
            "           4       0.78      0.61      0.68      1599\n",
            "           5       0.72      0.84      0.78      1598\n",
            "\n",
            "    accuracy                           0.87      7992\n",
            "   macro avg       0.87      0.87      0.87      7992\n",
            "weighted avg       0.87      0.87      0.87      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(300, 200),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 93.10247747747748\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      1.00      6393\n",
            "           2       1.00      1.00      1.00      6394\n",
            "           3       0.97      0.98      0.98      6394\n",
            "           4       0.89      0.78      0.83      6393\n",
            "           5       0.81      0.90      0.85      6394\n",
            "\n",
            "    accuracy                           0.93     31968\n",
            "   macro avg       0.93      0.93      0.93     31968\n",
            "weighted avg       0.93      0.93      0.93     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 90.990990990991\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      0.99      1599\n",
            "           2       0.99      1.00      0.99      1598\n",
            "           3       0.96      0.96      0.96      1598\n",
            "           4       0.84      0.73      0.79      1599\n",
            "           5       0.77      0.85      0.81      1598\n",
            "\n",
            "    accuracy                           0.91      7992\n",
            "   macro avg       0.91      0.91      0.91      7992\n",
            "weighted avg       0.91      0.91      0.91      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(600, 600),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 94.16916916916917\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      6393\n",
            "           2       1.00      1.00      1.00      6394\n",
            "           3       0.99      0.99      0.99      6394\n",
            "           4       0.90      0.81      0.86      6393\n",
            "           5       0.83      0.91      0.87      6394\n",
            "\n",
            "    accuracy                           0.94     31968\n",
            "   macro avg       0.94      0.94      0.94     31968\n",
            "weighted avg       0.94      0.94      0.94     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 91.8918918918919\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      1.00      1599\n",
            "           2       0.99      1.00      1.00      1598\n",
            "           3       0.97      0.98      0.97      1598\n",
            "           4       0.85      0.77      0.81      1599\n",
            "           5       0.79      0.85      0.82      1598\n",
            "\n",
            "    accuracy                           0.92      7992\n",
            "   macro avg       0.92      0.92      0.92      7992\n",
            "weighted avg       0.92      0.92      0.92      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(900, 900),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 94.16916916916917\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      6393\n",
            "           2       1.00      1.00      1.00      6394\n",
            "           3       0.99      0.99      0.99      6394\n",
            "           4       0.90      0.81      0.86      6393\n",
            "           5       0.83      0.91      0.87      6394\n",
            "\n",
            "    accuracy                           0.94     31968\n",
            "   macro avg       0.94      0.94      0.94     31968\n",
            "weighted avg       0.94      0.94      0.94     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 91.8918918918919\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      1.00      1599\n",
            "           2       0.99      1.00      1.00      1598\n",
            "           3       0.97      0.98      0.97      1598\n",
            "           4       0.85      0.77      0.81      1599\n",
            "           5       0.79      0.85      0.82      1598\n",
            "\n",
            "    accuracy                           0.92      7992\n",
            "   macro avg       0.92      0.92      0.92      7992\n",
            "weighted avg       0.92      0.92      0.92      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(900, 900),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=1000,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 75.15015015015015\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.92      0.90      6393\n",
            "           2       0.84      0.83      0.84      6394\n",
            "           3       0.69      0.81      0.75      6394\n",
            "           4       0.65      0.39      0.49      6393\n",
            "           5       0.68      0.81      0.74      6394\n",
            "\n",
            "    accuracy                           0.75     31968\n",
            "   macro avg       0.75      0.75      0.74     31968\n",
            "weighted avg       0.75      0.75      0.74     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 74.73723723723724\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.92      0.90      1599\n",
            "           2       0.84      0.84      0.84      1598\n",
            "           3       0.69      0.79      0.74      1598\n",
            "           4       0.63      0.38      0.47      1599\n",
            "           5       0.67      0.81      0.73      1598\n",
            "\n",
            "    accuracy                           0.75      7992\n",
            "   macro avg       0.74      0.75      0.74      7992\n",
            "weighted avg       0.74      0.75      0.74      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=2000,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 75.15015015015015\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.92      0.90      6393\n",
            "           2       0.84      0.83      0.84      6394\n",
            "           3       0.69      0.81      0.75      6394\n",
            "           4       0.65      0.39      0.49      6393\n",
            "           5       0.68      0.81      0.74      6394\n",
            "\n",
            "    accuracy                           0.75     31968\n",
            "   macro avg       0.75      0.75      0.74     31968\n",
            "weighted avg       0.75      0.75      0.74     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 74.73723723723724\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.92      0.90      1599\n",
            "           2       0.84      0.84      0.84      1598\n",
            "           3       0.69      0.79      0.74      1598\n",
            "           4       0.63      0.38      0.47      1599\n",
            "           5       0.67      0.81      0.73      1598\n",
            "\n",
            "    accuracy                           0.75      7992\n",
            "   macro avg       0.74      0.75      0.74      7992\n",
            "weighted avg       0.74      0.75      0.74      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=4000,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Label: ['5']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Define and train your classifier\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are defined\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Assuming vectorizer is defined\n",
        "\n",
        "# Sample comment\n",
        "student_comment = \"This course is amazing! I learned a lot and the instructor was very helpful.\"\n",
        "\n",
        "# Preprocess the comment\n",
        "def preprocess_comment(comment):\n",
        "    # Remove URLs, emails, and special characters\n",
        "    comment = re.sub(r'http\\S+|www.\\S+|[^a-zA-Z\\s]', '', comment)\n",
        "\n",
        "    # Remove numbers\n",
        "    comment = re.sub(r'\\d+', '', comment)\n",
        "\n",
        "    # Remove non-ASCII characters\n",
        "    comment = re.sub(r'[^\\x00-\\x7F]+', '', comment)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    comment = comment.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(comment)\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Preprocess the comment\n",
        "preprocessed_comment = preprocess_comment(student_comment)\n",
        "\n",
        "# Vectorize the comment using the same TF-IDF vectorizer used in training\n",
        "comment_vector = vectorizer.transform([preprocessed_comment])\n",
        "\n",
        "# Predict the label for the comment\n",
        "predicted_label = classifier.predict(comment_vector)\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Testing set results:\n",
            "Accuracy (in %): 80.70570570570571\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.97      0.96      1599\n",
            "           2       0.90      0.93      0.92      1598\n",
            "           3       0.78      0.85      0.81      1598\n",
            "           4       0.66      0.50      0.57      1599\n",
            "           5       0.71      0.79      0.75      1598\n",
            "\n",
            "    accuracy                           0.81      7992\n",
            "   macro avg       0.80      0.81      0.80      7992\n",
            "weighted avg       0.80      0.81      0.80      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier with specified hyperparameters\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVC Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "[LibSVM]Training set results:\n",
            "Accuracy (in %): 88.56981981981981\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      1.00      0.99      6393\n",
            "           2       0.95      0.99      0.97      6394\n",
            "           3       0.89      0.94      0.92      6394\n",
            "           4       0.79      0.72      0.76      6393\n",
            "           5       0.80      0.77      0.79      6394\n",
            "\n",
            "    accuracy                           0.89     31968\n",
            "   macro avg       0.88      0.89      0.88     31968\n",
            "weighted avg       0.88      0.89      0.88     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 86.56156156156156\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      1.00      0.99      1599\n",
            "           2       0.94      1.00      0.97      1598\n",
            "           3       0.89      0.92      0.90      1598\n",
            "           4       0.73      0.68      0.70      1599\n",
            "           5       0.77      0.73      0.75      1598\n",
            "\n",
            "    accuracy                           0.87      7992\n",
            "   macro avg       0.86      0.87      0.86      7992\n",
            "weighted avg       0.86      0.87      0.86      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create an SVC with specified hyperparameters\n",
        "classifier = SVC(C=1.0, kernel='linear', random_state=42, verbose=True)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training and testing sets\n",
        "y_train_pred = classifier.predict(X_train)\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "[LibSVM]Training set results:\n",
            "Accuracy (in %): 91.37262262262263\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      1.00      6393\n",
            "           2       0.98      1.00      0.99      6394\n",
            "           3       0.93      0.98      0.96      6394\n",
            "           4       0.82      0.80      0.81      6393\n",
            "           5       0.83      0.79      0.81      6394\n",
            "\n",
            "    accuracy                           0.91     31968\n",
            "   macro avg       0.91      0.91      0.91     31968\n",
            "weighted avg       0.91      0.91      0.91     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 88.6011011011011\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      1.00      0.99      1599\n",
            "           2       0.97      1.00      0.99      1598\n",
            "           3       0.91      0.97      0.94      1598\n",
            "           4       0.76      0.75      0.75      1599\n",
            "           5       0.79      0.71      0.75      1598\n",
            "\n",
            "    accuracy                           0.89      7992\n",
            "   macro avg       0.88      0.89      0.88      7992\n",
            "weighted avg       0.88      0.89      0.88      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create an SVC with specified hyperparameters\n",
        "classifier = SVC(C=10.0, kernel='linear', random_state=42, verbose=True)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training and testing sets\n",
        "y_train_pred = classifier.predict(X_train)\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "[LibSVM]Training set results:\n",
            "Accuracy (in %): 98.39214214214215\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      6393\n",
            "           2       1.00      1.00      1.00      6394\n",
            "           3       1.00      1.00      1.00      6394\n",
            "           4       0.98      0.94      0.96      6393\n",
            "           5       0.95      0.98      0.96      6394\n",
            "\n",
            "    accuracy                           0.98     31968\n",
            "   macro avg       0.98      0.98      0.98     31968\n",
            "weighted avg       0.98      0.98      0.98     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 96.09609609609609\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      1599\n",
            "           2       1.00      1.00      1.00      1598\n",
            "           3       1.00      0.99      1.00      1598\n",
            "           4       0.96      0.85      0.90      1599\n",
            "           5       0.87      0.96      0.91      1598\n",
            "\n",
            "    accuracy                           0.96      7992\n",
            "   macro avg       0.96      0.96      0.96      7992\n",
            "weighted avg       0.96      0.96      0.96      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create an SVC with specified hyperparameters\n",
        "classifier = SVC(C=1.0, random_state=42, verbose=True)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training and testing sets\n",
        "y_train_pred = classifier.predict(X_train)\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NaiveBayees Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 71.75613113113113\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.72      0.97      0.83      6393\n",
            "           2       0.74      0.90      0.81      6394\n",
            "           3       0.72      0.72      0.72      6394\n",
            "           4       0.58      0.48      0.53      6393\n",
            "           5       0.85      0.51      0.64      6394\n",
            "\n",
            "    accuracy                           0.72     31968\n",
            "   macro avg       0.72      0.72      0.71     31968\n",
            "weighted avg       0.72      0.72      0.71     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 69.84484484484484\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.97      0.83      1599\n",
            "           2       0.72      0.90      0.80      1598\n",
            "           3       0.70      0.71      0.70      1598\n",
            "           4       0.53      0.44      0.48      1599\n",
            "           5       0.81      0.48      0.60      1598\n",
            "\n",
            "    accuracy                           0.70      7992\n",
            "   macro avg       0.70      0.70      0.68      7992\n",
            "weighted avg       0.70      0.70      0.68      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Naive Bayes Classifier\n",
        "classifier = GaussianNB(var_smoothing=1e-2)\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 75.51926926926927\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.90      0.89      6393\n",
            "           2       0.81      0.85      0.83      6394\n",
            "           3       0.73      0.77      0.75      6394\n",
            "           4       0.63      0.50      0.56      6393\n",
            "           5       0.71      0.75      0.73      6394\n",
            "\n",
            "    accuracy                           0.76     31968\n",
            "   macro avg       0.75      0.76      0.75     31968\n",
            "weighted avg       0.75      0.76      0.75     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 74.86236236236236\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.91      0.89      1599\n",
            "           2       0.79      0.86      0.82      1598\n",
            "           3       0.74      0.76      0.75      1598\n",
            "           4       0.61      0.48      0.54      1599\n",
            "           5       0.69      0.73      0.71      1598\n",
            "\n",
            "    accuracy                           0.75      7992\n",
            "   macro avg       0.74      0.75      0.74      7992\n",
            "weighted avg       0.74      0.75      0.74      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Function to process data in batches\n",
        "def batch_generator(X, y, batch_size):\n",
        "    n_samples = X.shape[0]\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Naive Bayes Classifier\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "# Train the classifier in batches\n",
        "for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
        "    classifier.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
        "\n",
        "# Predict in batches for train data\n",
        "y_train_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_train, y_train, batch_size)\n",
        "])\n",
        "\n",
        "# Predict in batches for test data\n",
        "y_test_pred = np.concatenate([\n",
        "    classifier.predict(X_batch)\n",
        "    for X_batch, _ in batch_generator(X_test, y_test, batch_size)\n",
        "])\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GradientBoostingAlgorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: Index(['10', '100', 'abil', 'abl', 'about', 'absolut', 'academ', 'access',\n",
            "       'accomplish', 'account',\n",
            "       ...\n",
            "       'write', 'written', 'wrong', 'yaakov', 'year', 'yet', 'you', 'your',\n",
            "       'yourself', 'Label'],\n",
            "      dtype='object', length=1001)\n",
            "Training set results:\n",
            "Accuracy (in %): 81.87875375375376\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92      6393\n",
            "           2       0.94      0.89      0.92      6394\n",
            "           3       0.82      0.83      0.82      6394\n",
            "           4       0.70      0.62      0.66      6393\n",
            "           5       0.72      0.84      0.77      6394\n",
            "\n",
            "    accuracy                           0.82     31968\n",
            "   macro avg       0.82      0.82      0.82     31968\n",
            "weighted avg       0.82      0.82      0.82     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 79.70470470470471\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.90      0.91      1599\n",
            "           2       0.92      0.89      0.90      1598\n",
            "           3       0.81      0.80      0.81      1598\n",
            "           4       0.67      0.58      0.62      1599\n",
            "           5       0.68      0.81      0.74      1598\n",
            "\n",
            "    accuracy                           0.80      7992\n",
            "   macro avg       0.80      0.80      0.80      7992\n",
            "weighted avg       0.80      0.80      0.80      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Verify the columns in the DataFrame\n",
        "print(\"Columns in DataFrame:\", resampled_df.columns)\n",
        "\n",
        "# Ensure the DataFrame contains the 'Label' column\n",
        "if 'Label' not in resampled_df.columns:\n",
        "    raise ValueError(\"The DataFrame does not contain 'Label' column\")\n",
        "\n",
        "# Separate the features and labels\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.drop(columns=['Label'])\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Parameters\n",
        "batch_size = 10000  # Adjust batch size according to your memory constraints\n",
        "\n",
        "# Create a Gradient Boosting Classifier with specified hyperparameters\n",
        "classifier = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict for train data\n",
        "y_train_pred = classifier.predict(X_train)\n",
        "\n",
        "# Predict for test data\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPomcZ8I0p07",
        "outputId": "73076b5b-8053-43b1-d01c-b75bdd336468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 78.71308808808809\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.89      0.91      6393\n",
            "           2       0.94      0.88      0.91      6394\n",
            "           3       0.77      0.87      0.81      6394\n",
            "           4       0.68      0.56      0.61      6393\n",
            "           5       0.64      0.73      0.68      6394\n",
            "\n",
            "    accuracy                           0.79     31968\n",
            "   macro avg       0.79      0.79      0.79     31968\n",
            "weighted avg       0.79      0.79      0.79     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 74.54954954954955\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.87      0.88      1599\n",
            "           2       0.90      0.85      0.88      1598\n",
            "           3       0.73      0.81      0.77      1598\n",
            "           4       0.61      0.48      0.54      1599\n",
            "           5       0.61      0.71      0.66      1598\n",
            "\n",
            "    accuracy                           0.75      7992\n",
            "   macro avg       0.75      0.75      0.74      7992\n",
            "weighted avg       0.75      0.75      0.74      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Create a pipeline object with the preprocessor and Decision Tree Classifier with specified hyperparameters\n",
        "pipeline = Pipeline([\n",
        "    ('DTC', DecisionTreeClassifier(\n",
        "        max_depth=30,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=4,\n",
        "        max_features='sqrt',\n",
        "        random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs4CdXUV-SRA",
        "outputId": "26f1af53-e178-4762-c2b9-9b0533b28c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 79.66403903903904\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.90      0.91      6393\n",
            "           2       0.91      0.86      0.89      6394\n",
            "           3       0.82      0.79      0.81      6394\n",
            "           4       0.66      0.59      0.62      6393\n",
            "           5       0.68      0.84      0.76      6394\n",
            "\n",
            "    accuracy                           0.80     31968\n",
            "   macro avg       0.80      0.80      0.80     31968\n",
            "weighted avg       0.80      0.80      0.80     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 77.42742742742743\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.88      0.90      1599\n",
            "           2       0.90      0.86      0.88      1598\n",
            "           3       0.80      0.76      0.78      1598\n",
            "           4       0.62      0.54      0.58      1599\n",
            "           5       0.66      0.83      0.74      1598\n",
            "\n",
            "    accuracy                           0.77      7992\n",
            "   macro avg       0.78      0.77      0.77      7992\n",
            "weighted avg       0.78      0.77      0.77      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create a pipeline object with the preprocessor and Gradient Boosting Classifier with specified hyperparameters\n",
        "pipeline = Pipeline([\n",
        "    ('GBC', GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        max_features='sqrt',\n",
        "        subsample=0.8,\n",
        "        random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ119L3l-kIL",
        "outputId": "ae6fa5b1-1229-42a6-ebec-9294c619f72c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 82.83283283283284\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.95      0.94      6393\n",
            "           2       0.94      0.90      0.92      6394\n",
            "           3       0.85      0.82      0.84      6394\n",
            "           4       0.71      0.62      0.66      6393\n",
            "           5       0.73      0.85      0.78      6394\n",
            "\n",
            "    accuracy                           0.83     31968\n",
            "   macro avg       0.83      0.83      0.83     31968\n",
            "weighted avg       0.83      0.83      0.83     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 81.44394394394394\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.94      0.93      1599\n",
            "           2       0.93      0.89      0.91      1598\n",
            "           3       0.85      0.81      0.83      1598\n",
            "           4       0.69      0.59      0.64      1599\n",
            "           5       0.70      0.84      0.77      1598\n",
            "\n",
            "    accuracy                           0.81      7992\n",
            "   macro avg       0.82      0.81      0.81      7992\n",
            "weighted avg       0.82      0.81      0.81      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create a pipeline object with the preprocessor and Gradient Boosting Classifier with specified hyperparameters\n",
        "pipeline = Pipeline([\n",
        "    ('GBC', GradientBoostingClassifier(\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        min_samples_split=300,\n",
        "        min_samples_leaf=300,\n",
        "        max_features='sqrt',\n",
        "        subsample=0.8,\n",
        "        random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofuDPangAEe3",
        "outputId": "fb9bd165-e6c4-4ed6-b05f-d84d6af61735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 94.7947947947948\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      6393\n",
            "           2       1.00      0.99      0.99      6394\n",
            "           3       0.98      0.98      0.98      6394\n",
            "           4       0.92      0.84      0.88      6393\n",
            "           5       0.85      0.94      0.89      6394\n",
            "\n",
            "    accuracy                           0.95     31968\n",
            "   macro avg       0.95      0.95      0.95     31968\n",
            "weighted avg       0.95      0.95      0.95     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 91.14114114114115\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.99      0.99      1599\n",
            "           2       0.99      0.99      0.99      1598\n",
            "           3       0.95      0.95      0.95      1598\n",
            "           4       0.84      0.76      0.80      1599\n",
            "           5       0.79      0.88      0.83      1598\n",
            "\n",
            "    accuracy                           0.91      7992\n",
            "   macro avg       0.91      0.91      0.91      7992\n",
            "weighted avg       0.91      0.91      0.91      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create a pipeline object with the preprocessor and Gradient Boosting Classifier with specified hyperparameters\n",
        "pipeline = Pipeline([\n",
        "    ('GBC', GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.2,\n",
        "        max_depth=30,\n",
        "        min_samples_split=300,\n",
        "        min_samples_leaf=300,\n",
        "        max_features='sqrt',\n",
        "        subsample=0.8,\n",
        "        random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYB-lzs-BTzj",
        "outputId": "4aa29e6a-c73b-40c8-92da-b4994ce8886a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 99.35247747747748\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      6393\n",
            "           2       1.00      1.00      1.00      6394\n",
            "           3       1.00      1.00      1.00      6394\n",
            "           4       0.98      0.99      0.99      6393\n",
            "           5       0.99      0.98      0.99      6394\n",
            "\n",
            "    accuracy                           0.99     31968\n",
            "   macro avg       0.99      0.99      0.99     31968\n",
            "weighted avg       0.99      0.99      0.99     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 94.76976976976978\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      1.00      1599\n",
            "           2       0.99      1.00      1.00      1598\n",
            "           3       0.97      1.00      0.98      1598\n",
            "           4       0.84      0.96      0.89      1599\n",
            "           5       0.96      0.78      0.86      1598\n",
            "\n",
            "    accuracy                           0.95      7992\n",
            "   macro avg       0.95      0.95      0.95      7992\n",
            "weighted avg       0.95      0.95      0.95      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create a pipeline object with the preprocessor and MLPClassifier with specified hyperparameters\n",
        "pipeline = Pipeline([\n",
        "    ('MLP', MLPClassifier(\n",
        "        hidden_layer_sizes=(100, 50),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        learning_rate_init=0.001,\n",
        "        max_iter=200,\n",
        "        batch_size=32,\n",
        "        random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L46WmmbZChRA",
        "outputId": "23095b47-442a-4fa0-b699-b20439358934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 94.08783783783784\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      0.99      6393\n",
            "           2       0.99      0.99      0.99      6394\n",
            "           3       0.97      0.99      0.98      6394\n",
            "           4       0.86      0.89      0.88      6393\n",
            "           5       0.89      0.83      0.86      6394\n",
            "\n",
            "    accuracy                           0.94     31968\n",
            "   macro avg       0.94      0.94      0.94     31968\n",
            "weighted avg       0.94      0.94      0.94     31968\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 91.74174174174175\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      1.00      0.99      1599\n",
            "           2       0.98      0.99      0.99      1598\n",
            "           3       0.96      0.98      0.97      1598\n",
            "           4       0.81      0.85      0.83      1599\n",
            "           5       0.85      0.77      0.81      1598\n",
            "\n",
            "    accuracy                           0.92      7992\n",
            "   macro avg       0.92      0.92      0.92      7992\n",
            "weighted avg       0.92      0.92      0.92      7992\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create a pipeline object with the preprocessor and MLPClassifier with specified hyperparameters\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('MLP', MLPClassifier(\n",
        "        hidden_layer_sizes=(100, 50),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        learning_rate_init=0.001,\n",
        "        max_iter=400,\n",
        "        batch_size=32,\n",
        "        random_state=42,\n",
        "        alpha=0.1,  # L2 regularization parameter\n",
        "        early_stopping=True,  # Enable early stopping\n",
        "    ))\n",
        "])\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M97zA3GIFCg9",
        "outputId": "94ed0b72-1710-463c-dae2-7bce8f314b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11255, 1000)\n",
            "(11255,)\n"
          ]
        }
      ],
      "source": [
        "resampled_df = resampled_df.dropna(subset=['Label'])\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "y = resampled_df['Label']\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "zu0H-3o0FD2B"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv_F7bIYFG30",
        "outputId": "9abd7702-abf5-4d2d-b666-95076dfa903e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1' '2' '3' '4' '5']\n"
          ]
        }
      ],
      "source": [
        "print(resampled_df['Label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Ai65nTFJYR",
        "outputId": "5a874e9e-aa88-4c50-9692-02097e2242f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9004 9004\n",
            "2251 2251\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train), len(y_train))\n",
        "print(len(X_test), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnO57ZHFW8I",
        "outputId": "e47b410e-c3eb-4a33-b83e-b19f9981d1f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set results:\n",
            "Accuracy (in %): 54.82007996446024\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      0.65      0.63      1801\n",
            "           2       0.45      0.40      0.42      1801\n",
            "           3       0.45      0.52      0.48      1801\n",
            "           4       0.52      0.38      0.44      1800\n",
            "           5       0.67      0.80      0.73      1801\n",
            "\n",
            "    accuracy                           0.55      9004\n",
            "   macro avg       0.54      0.55      0.54      9004\n",
            "weighted avg       0.54      0.55      0.54      9004\n",
            "\n",
            "Testing set results:\n",
            "Accuracy (in %): 49.31141714793425\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.57      0.62      0.59       450\n",
            "           2       0.39      0.35      0.37       450\n",
            "           3       0.41      0.46      0.43       450\n",
            "           4       0.44      0.30      0.36       451\n",
            "           5       0.62      0.73      0.67       450\n",
            "\n",
            "    accuracy                           0.49      2251\n",
            "   macro avg       0.48      0.49      0.48      2251\n",
            "weighted avg       0.48      0.49      0.48      2251\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "y = resampled_df['Label']\n",
        "X = resampled_df.loc[:, resampled_df.columns != 'Label']\n",
        "\n",
        "# Split your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Create a pipeline object with the preprocessor and MLPClassifier with specified hyperparameters\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('MLP', MLPClassifier(\n",
        "        hidden_layer_sizes=(100, 50),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        learning_rate_init=0.001,\n",
        "        max_iter=400,\n",
        "        batch_size=32,\n",
        "        random_state=42,\n",
        "        alpha=0.1,  # L2 regularization parameter\n",
        "        early_stopping=True,  # Enable early stopping\n",
        "    ))\n",
        "])\n",
        "# Fit the pipeline with the text data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get the prediction for X_train and X_test\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the training set\n",
        "print(\"Training set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))\n",
        "\n",
        "# Compute and print the accuracy, precision, recall, and F1-score for the testing set\n",
        "print(\"Testing set results:\")\n",
        "print(\"Accuracy (in %):\", metrics.accuracy_score(y_test, y_test_pred) * 100)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec67_8gA2nBS",
        "outputId": "1a7efe03-0780-47d8-8ad8-3150cd6e2607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZhZOQIIo65d",
        "outputId": "1bb22757-5161-4584-a48f-4d4448f0f232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Classifier accuracy (in %) for training set: 79.12607751068751\n",
            "SVM Classifier accuracy (in %) for testing set: 77.35002803214353\n",
            "For SVM Classifier using TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.54      0.39      0.45       493\n",
            "           2       0.36      0.12      0.18       484\n",
            "           3       0.30      0.14      0.19       933\n",
            "           4       0.49      0.20      0.28      3613\n",
            "           5       0.81      0.97      0.89     15881\n",
            "\n",
            "    accuracy                           0.77     21404\n",
            "   macro avg       0.50      0.36      0.40     21404\n",
            "weighted avg       0.72      0.77      0.73     21404\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Apply preprocessing to the text data\n",
        "X = X.apply(preprocess_text)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define the classifier\n",
        "clf = SVC(kernel='linear', C=1.0)\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = clf.predict(X_train_tfidf)\n",
        "y_test_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Classifier accuracy (in %) for training set:\", accuracy_score(y_train, y_train_pred) * 100)\n",
        "print(\"SVM Classifier accuracy (in %) for testing set:\", accuracy_score(y_test, y_test_pred) * 100)\n",
        "\n",
        "# Print the classification report\n",
        "print('For SVM Classifier using TF-IDF')\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Label: ['2']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['classifier.h5']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming resampled_df is your DataFrame after balancing\n",
        "# Define and train your classifier\n",
        "classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=100,\n",
        "    random_state=42)\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are defined\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Assuming vectorizer is defined and trained\n",
        "\n",
        "# Sample comment\n",
        "student_comment = \"This course is not good  enough.\"\n",
        "\n",
        "# Preprocess the comment\n",
        "def preprocess_comment(comment):\n",
        "    # Remove URLs, emails, and special characters\n",
        "    comment = re.sub(r'http\\S+|www.\\S+|[^a-zA-Z\\s]', '', comment)\n",
        "\n",
        "    # Remove numbers\n",
        "    comment = re.sub(r'\\d+', '', comment)\n",
        "\n",
        "    # Remove non-ASCII characters\n",
        "    comment = re.sub(r'[^\\x00-\\x7F]+', '', comment)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    comment = comment.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(comment)\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Preprocess the comment\n",
        "preprocessed_comment = preprocess_comment(student_comment)\n",
        "\n",
        "# Vectorize the comment using the same TF-IDF vectorizer used in training\n",
        "comment_vector = vectorizer.transform([preprocessed_comment])\n",
        "\n",
        "# Predict the label for the comment\n",
        "predicted_label = classifier.predict(comment_vector)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)\n",
        "# Save the trained classifier\n",
        "joblib.dump(classifier, 'classifier.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['classifier_model.h5']"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(classifier, 'classifier_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from h5py) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py\n",
        "import pickle\n",
        "\n",
        "# Save the trained classifier\n",
        "with open('classifier_model.pkl', 'wb') as f:\n",
        "    pickle.dump(classifier, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['classifier.h5',\n",
              " 'classifier_model.h5',\n",
              " 'classifier_model.pkl',\n",
              " 'reviews.csv',\n",
              " 'reviews_by_course.csv',\n",
              " 'Untitled27 (4).ipynb']"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier saved to classifier_model.h5\n",
            "Vectorizer saved to vectorizer.h5\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Define the path to save the classifier and vectorizer\n",
        "classifier_path = 'classifier_model.h5'\n",
        "vectorizer_path = 'vectorizer.h5'\n",
        "\n",
        "# Save the trained classifier\n",
        "joblib.dump(classifier, classifier_path)\n",
        "print(f\"Classifier saved to {classifier_path}\")\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "joblib.dump(vectorizer, vectorizer_path)\n",
        "print(f\"Vectorizer saved to {vectorizer_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(vectorizer, vectorizer_path)\n",
        "print(f\"Vectorizer saved to {vectorizer_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
